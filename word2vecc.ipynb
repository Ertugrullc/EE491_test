{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('trmodel', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "from os.path import basename\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "SAMPLE_FILE_NAME = \"all_words.txt\"\n",
    "PY_MODULE_PATH = \"cleared_samples\"\n",
    "FILE_NAME = 'all_words.txt'\n",
    "PATH_OF_SAMPLES = [os.path.join(PY_MODULE_PATH, file) for file in os.listdir(PY_MODULE_PATH)]\n",
    "ZERO_KEY = \"<ZERO>\"\n",
    "\n",
    "\n",
    "def get_txts():\n",
    "    remov = set(stopwords.words(\"turkish\"))\n",
    "    topic_dict = {}\n",
    "    for path in PATH_OF_SAMPLES:\n",
    "        class_name = basename(path)\n",
    "        with open(os.path.join(path, FILE_NAME),'r',encoding=\"utf-8\",errors='ignore') as f:\n",
    "            words = f.readlines()\n",
    "            words = [w.strip() for w in words if '\\n' != w]\n",
    "            words_list = [w for w in words if w not in remov]\n",
    "            words_list = [x for x in words_list if not any(c.isdigit() for c in x)]\n",
    "            words_list = filter (lambda word: len (word) > 2, words_list)\n",
    "            topic_dict[class_name] = words_list\n",
    "    return topic_dict\n",
    "\n",
    "# print(\"0\" in my_dict[\"dunya\"])\n",
    "\n",
    "def word_dict_f(my_dict):\n",
    "    all_words = [w for key in my_dict for w in my_dict[key]]\n",
    "    count_dict = Counter(all_words)\n",
    "    sorted_dict = {k: v for k, v in sorted(count_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_dict\n",
    "    \n",
    "my_dict = get_txts()\n",
    "word_dict = word_dict_f(my_dict)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "THRESHOLD_TXT_WORD = 20\n",
    "BASE_PATH = \"42bin_haber/news\"\n",
    "\n",
    "PATHS_OF_CLASSES = [os.path.join(BASE_PATH, file) for file in os.listdir(BASE_PATH)]\n",
    "\n",
    "def get_training_data_w2v(PATHS_OF_CLASSES, word_dict, word_vectors):\n",
    "    \n",
    "    vec_mat_y = np.eye(len(PATHS_OF_CLASSES))\n",
    "    dict_y = {basename(path): vec_mat_y[PATHS_OF_CLASSES.index(path)] for path in PATHS_OF_CLASSES}\n",
    "    training_data = []\n",
    "    ##\n",
    "    folder = 0\n",
    "    ##\n",
    "    for path in PATHS_OF_CLASSES:\n",
    "        class_name = basename(path)\n",
    "        y_data = dict_y[class_name]\n",
    "        ##\n",
    "        fil = 0\n",
    "        ##\n",
    "        for file in os.listdir(path):\n",
    "            fil+=1\n",
    "            print(class_name,\":\",fil)\n",
    "            if file.endswith('.txt'):\n",
    "                with open(os.path.join(path, file),'r',encoding=\"utf-8\",errors='ignore') as f:\n",
    "                    text = f.read()\n",
    "                    word_list = clear_sample(text, word_dict, word_vectors)   ## you can change clear type by writing new function\n",
    "                    X_data = [word_vectors[w] for w in word_list]\n",
    "                    training_data.append([X_data, y_data])\n",
    "    \n",
    "    return training_data\n",
    "                    \n",
    "        \n",
    "def clear_sample(text, word_dict, word_vectors):\n",
    "    remov = set(stopwords.words(\"turkish\"))\n",
    "    words = word_tokenize(text)\n",
    "    result_words = []\n",
    "    for w in words:\n",
    "        temp = w.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).split()\n",
    "        result_words.extend(t for t in temp)\n",
    "        \n",
    "    words = [word.lower() for word in result_words]\n",
    "    words = [w.strip() for w in words if '\\n' or '' != w]\n",
    "    words = [w for w in words if w not in remov]\n",
    "    words = [x for x in words if not any(c.isdigit() for c in x)]\n",
    "    words = filter (lambda word: len (word) > 2, words)\n",
    "    \n",
    "    w_list = []\n",
    "    \n",
    "    for w in words:\n",
    "        if (w in word_dict) and (w in word_vectors.vocab):\n",
    "            w_list.append(w)\n",
    "        if len(w_list) == THRESHOLD_TXT_WORD:\n",
    "            break\n",
    "    \n",
    "    while len(w_list) < THRESHOLD_TXT_WORD:\n",
    "        w_list.append(ZERO_KEY)\n",
    "        \n",
    "    return w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "VEC_SIZE = len(word_vectors[\"bir\"])\n",
    "zero_vec = np.float32(np.zeros((1,400),dtype=float)[0])\n",
    "word_vectors.add(ZERO_KEY,zero_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = get_training_data_w2v(PATHS_OF_CLASSES, word_dict, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(training_data)\n",
    "np.save(\"training_data_w2v_shuffled.npy\", training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}