{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from txt_to_dict import get_txts\n",
    "\n",
    "topics = get_txts()\n",
    "\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "\n",
    "trainset = np.load('training_data_w2v_shuffled.npy',allow_pickle=True)\n",
    "trainset1 = trainset[0:int(len(trainset)*0.8)]\n",
    "trainset2 = trainset[int(len(trainset)*0.8):int(len(trainset)*0.9)]\n",
    "testset = trainset[int(len(trainset)*0.9):len(trainset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainset[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(20*400,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,13)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    EPOCHS = 6\n",
    "    BATCH_SIZE = 32\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(trainset1)-BATCH_SIZE, BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "            \n",
    "#           X, y = torch.from_numpy(trainset1[i:i+BATCH_SIZE]).to(device)\n",
    "            X = torch.empty(BATCH_SIZE, len(trainset[0][0][0])*20)\n",
    "            for j in range(BATCH_SIZE):\n",
    "                txt = np.array([])\n",
    "                for k in range(20):\n",
    "                    word = trainset1[i+j-1][0][k]\n",
    "                    txt = np.append(txt, word)\n",
    "                X[j] = torch.from_numpy(txt)\n",
    "            y = torch.empty(BATCH_SIZE, 13)\n",
    "            for j in range(BATCH_SIZE):\n",
    "                y[j] = torch.from_numpy(trainset1[i+j-1][1])\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            net.zero_grad()\n",
    "            \n",
    "            outputs = net(X)\n",
    "            loss = loss_function(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(testset))):\n",
    "            real_class = torch.argmax(torch.from_numpy(testset[i][1])).to(device)\n",
    "            try:\n",
    "                txt = torch.from_numpy(np.append([],testset[i][0]))\n",
    "            except:\n",
    "                dum = np.array([])\n",
    "                for j in range(20):\n",
    "                    if (len(testset[i][0][j])==20):\n",
    "                        dum = np.append(dum, testset[i][0][j])\n",
    "                    else:\n",
    "                        dum = np.append(dum, testset[i][0][j][0])\n",
    "            txt = txt.float()\n",
    "            net_out = net(txt.view(-1,len(txt)).to(device))[0]  # returns a list, \n",
    "            predicted_class = torch.argmax(net_out)\n",
    "\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy: \", round(correct/total, 3))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train = False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss = loss_function(outputs, y)\n",
    "\n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(size=32):\n",
    "    i = randint(0,len(testset)-size-1)\n",
    "    X = torch.empty(size, len(testset[0][0][0])*20)\n",
    "    for j in range(size):\n",
    "        txt = np.array([])\n",
    "        for k in range(20):\n",
    "            word = testset[i+j-1][0][k]\n",
    "            txt = np.append(txt, word)\n",
    "        X[j] = torch.from_numpy(txt)\n",
    "    y = torch.empty(size, 13)\n",
    "    for j in range(size):\n",
    "        y[j] = torch.from_numpy(testset[i+j-1][1])\n",
    "    val_acc, val_loss = fwd_pass(X.view(-1,len(testset[0][0][0])*20).to(device), y.to(device))\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=8000, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=13, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1049/1049 [00:16<00:00, 62.73it/s]\n",
      "100%|██████████| 1049/1049 [00:15<00:00, 69.80it/s]\n",
      "100%|██████████| 1049/1049 [00:14<00:00, 70.54it/s]\n",
      "100%|██████████| 1049/1049 [00:14<00:00, 70.14it/s]\n",
      "100%|██████████| 1049/1049 [00:15<00:00, 69.74it/s]\n",
      "100%|██████████| 1049/1049 [00:16<00:00, 61.97it/s]\n",
      "100%|██████████| 1049/1049 [00:17<00:00, 58.57it/s]\n",
      "100%|██████████| 1049/1049 [00:14<00:00, 70.24it/s]\n",
      "100%|██████████| 1049/1049 [00:14<00:00, 70.36it/s]\n",
      "100%|██████████| 1049/1049 [00:14<00:00, 70.59it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "def train_(net):\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "\n",
    "    with open(\"model_w2v.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, len(trainset1)-BATCH_SIZE, BATCH_SIZE)):\n",
    "                \n",
    "                X = torch.empty(BATCH_SIZE, len(trainset[0][0][0])*20)\n",
    "                for j in range(BATCH_SIZE):\n",
    "                    txt = np.array([])\n",
    "                    for k in range(20):\n",
    "                        word = trainset1[i+j-1][0][k]\n",
    "                        txt = np.append(txt, word)\n",
    "                    X[j] = torch.from_numpy(txt)\n",
    "                y = torch.empty(BATCH_SIZE, 13)\n",
    "                for j in range(BATCH_SIZE):\n",
    "                    y[j] = torch.from_numpy(trainset1[i+j-1][1])\n",
    "\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                acc, loss = fwd_pass(X, y, train=True)\n",
    "\n",
    "                #print(f\"Acc: {round(float(acc),2)}  Loss: {round(float(loss),4)}\")\n",
    "                #f.write(f\"{MODEL_NAME},{round(time.time(),3)},train,{round(float(acc),2)},{round(float(loss),4)}\\n\")\n",
    "                # just to show the above working, and then get out:\n",
    "                if i % 50 == 0:\n",
    "                    val_acc, val_loss = test_(size=32)\n",
    "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),2)},{round(float(loss), 4)},{round(float(val_acc),2)},{round(float(val_loss),4)}\\n\")\n",
    "train_(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "haber = \"Tunus Savunma Bakanlığı, ANKA-S İHA alımı için TUSAŞ ile sözleşme imzaladı. Anlaşma, 3 adet ANKA-S İHA ve 3 adet yer kontrol istasyonunun teslimi ile 52 Tunus Hava Kuvvetleri personelinin eğitimini kapsıyor. İhracatın 80 milyon dolar tutarında olduğu belirtildi.İHA ve SİHA düzenlenen askeri operasyonlarda adından söz ettiren Türkiye, Katar ve Ukrayna'nın ardından Tunus'a da satış gerçekleştirecek.Türk Havacılık ve Uzay Sanayii (TUSAŞ), tarihinde ilk kez milli ve yerli tasarım insansız hava aracı ANKA-S'nin ihracatına imza attı.TUNUS'A ANKA-S İHRACATI2019 yılında başlayan ve anlaşmaya varılan görüşmeler sonucunda Tunus Hava Kuvvetleri Komutanlığı'na 3 adet ANKA-S İHA ve 3 adet Yer Kontrol Sistemi sağlanacak.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
